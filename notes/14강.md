# 14. Orchestration 1. 태스크, 서비스, 클러스터 개념정리

# 핵심 정리

## 🎯 학습 목표

이 튜토리얼을 마치면 다음을 할 수 있습니다:

- 서버 배포의 기본 개념 이해
- 마이크로서비스 아키텍처의 장단점 파악
- Container Orchestration의 필요성 이해
- AWS ECS의 기본 구조 이해
- 로드 밸런서의 역할 파악
- ECS 배포를 위한 준비 과정 이해

---

## 📚 사전 지식

- Docker 기본 명령어 (build, run, push)
- Nginx 리버스 프록시 개념
- 포트와 네트워크 기본 개념
- AWS 계정 (실습용)

---

## 1단계: 서버 배포의 기본 이해

### 일반적인 배포 방식

서버를 만들었다면 다른 사람들이 접속할 수 있게 배포해야 합니다.

**집 컴퓨터에서 실행하는 경우:**

`[사용자] → [내 IP 주소:8080] → [내 컴퓨터의 서버]`

**문제점:**

- ❌ 24시간 컴퓨터를 켜두어야 함
- ❌ 가정용 인터넷은 IP 주소가 자주 바뀜
- ❌ 전기세와 성능 문제

**해결책: 클라우드 서버 사용**

`[사용자] → [AWS 서버 IP:8080] → [AWS의 서버]`

AWS, Google Cloud, Azure 등에서 컴퓨터를 빌려서 서버를 실행합니다.

### Docker를 활용한 배포

**전통적인 방법:**

1. AWS 컴퓨터에 접속
2. 필요한 프로그램 설치 (Node.js, Python 등)
3. 코드 업로드
4. 실행

**Docker를 사용한 방법:**

1. 내 코드를 Docker 이미지로 만들기
2. 이미지를 Docker Hub 같은 곳에 업로드
3. AWS 컴퓨터에서 이미지 다운로드
4. `docker run` 명령어로 실행

**장점:**

- ✅ 환경 설정이 이미지에 포함되어 있음
- ✅ 배포 과정이 매우 간단함
- ✅ 어디서든 동일하게 실행됨

---

## 2단계: 마이크로서비스란?

### 모놀리식 vs 마이크로서비스

**모놀리식 (Monolithic):**

`[하나의 큰 서버 프로그램]
├── 회원 기능
├── 게시판 기능
├── 결제 기능
└── 알림 기능`

모든 기능이 하나의 프로그램 안에 들어있습니다.

**마이크로서비스 (Microservices):**

`[회원 서버]  [게시판 서버]  [결제 서버]  [알림 서버]
    ↓            ↓            ↓            ↓
[컨테이너 1] [컨테이너 2] [컨테이너 3] [컨테이너 4]`

각 기능을 독립적인 프로그램으로 분리하여 각각 컨테이너로 실행합니다.

### 마이크로서비스의 장단점

**장점:**

- ✅ **확장성**: 트래픽이 많은 서비스만 서버를 늘릴 수 있음
- ✅ **독립 배포**: 한 기능만 수정해도 해당 서비스만 재배포 가능
- ✅ **장애 격리**: 한 서비스에 문제가 생겨도 다른 서비스는 정상 동작
- ✅ **기술 선택의 자유**: 각 서비스마다 다른 언어/프레임워크 사용 가능

**단점:**

- ❌ **복잡성 증가**: 관리해야 할 서비스가 많아짐
- ❌ **통신 오버헤드**: 서비스 간 네트워크 통신 필요
- ❌ **초기 비용**: 처음에는 서버 비용이 더 들 수 있음
- ❌ **관리 인력 필요**: 여러 서비스를 관리하는 인력과 시간 필요

### 언제 사용해야 할까?

**처음에는:**

`모든 기능을 하나의 프로그램에 넣어서 개발
(모놀리식 방식)`

**나중에:**

`특정 기능이 너무 크거나 자주 변경된다면
→ 그 부분만 마이크로서비스로 분리`

**핵심 원칙**: 처음부터 모든 것을 마이크로서비스로 만들지 말고, 필요할 때 점진적으로 분리하세요.

---

## 3단계: Container Orchestration 이해하기

### 왜 필요한가?

**문제 상황:**

`컨테이너가 10개, 20개, 100개...
각각 관리하기가 너무 복잡함!`

**Container Orchestration이 해결하는 것들:**

- 🎯 **자동 배포**: 컨테이너를 쉽게 띄우고 내릴 수 있음
- 🎯 **스케일링**: 트래픽에 따라 컨테이너 개수를 자동으로 조절
- 🎯 **자동 복구**: 컨테이너가 죽으면 자동으로 재시작
- 🎯 **로드 밸런싱**: 트래픽을 여러 컨테이너에 분산
- 🎯 **네트워크 관리**: 컨테이너 간 통신 설정

### 주요 도구들

**1. Kubernetes (쿠버네티스)**

- 가장 유명하고 강력함
- 복잡하지만 기능이 많음
- Google, AWS, Azure 모두 지원

**관리형 쿠버네티스 서비스:**

- Google Kubernetes Engine (GKE)
- Amazon Elastic Kubernetes Service (EKS)
- Azure Kubernetes Service (AKS)

**2. AWS ECS (Elastic Container Service)**

- AWS에서 만든 간단한 orchestration 도구
- 쿠버네티스보다 배우기 쉬움
- AWS 서비스와 잘 연동됨

**3. 간편 배포 서비스들:**

- Google Cloud Run
- AWS Elastic Beanstalk
- Fly.io
- Heroku
- Vercel

---

## 4단계: AWS ECS 구조 이해

### ECS의 계층 구조

`클러스터 (Cluster)
    ↓
서비스 (Service)
    ↓
태스크 (Task)
    ↓
컨테이너 (Container)`

**각 계층 설명:**

**1. 클러스터 (Cluster)**

- 전체 프로젝트를 담는 가장 큰 단위
- "우리 회사 서버들의 집합"

**2. 서비스 (Service)**

- 하나의 마이크로서비스를 의미
- 예: 회원 서비스, 게시판 서비스, 결제 서비스
- 태스크를 자동으로 복제하고 관리함

**3. 태스크 (Task)**

- 함께 실행되어야 하는 컨테이너들의 묶음
- Docker Compose와 비슷한 개념
- 예: Nginx + 웹서버 + DB를 하나의 태스크로 묶음

**4. 컨테이너 (Container)**

- 실제 프로그램이 실행되는 단위

### 실제 예시

**회원 서버 + 게시판 서버를 ECS로 배포:**

`[클러스터: 우리 프로젝트]
    │
    ├── [서비스 1: 회원 서비스]
    │       └── [태스크 1]
    │               ├── Nginx 컨테이너
    │               ├── 회원 웹서버 컨테이너
    │               └── DB 컨테이너
    │
    └── [서비스 2: 게시판 서비스]
            └── [태스크 1]
                    ├── Nginx 컨테이너
                    ├── 게시판 웹서버 컨테이너
                    └── DB 컨테이너`

**태스크 복제 예시:**

`[서비스: 회원 서비스]
    ├── [태스크 1] ← 컴퓨터 1에서 실행
    ├── [태스크 2] ← 컴퓨터 1에서 실행
    └── [태스크 3] ← 컴퓨터 2에서 실행`

- 트래픽이 많으면 태스크를 여러 개 복제
- 한 컴퓨터가 고장나도 다른 컴퓨터에서 계속 실행

### 치킨집 비유로 이해하기

**클러스터 = 프랜차이즈 본사**

`"치킨 브랜드 본사"`

**서비스 = 메뉴 카테고리**

`치킨 메뉴팀, 피자 메뉴팀`

**태스크 = 실제 매장**

`강남점, 신촌점, 홍대점`

**컨테이너 = 매장 안의 직원/장비**

`주방장(웹서버), 홀 매니저(Nginx), 재고 관리자(DB)`

**예시:**

`[치킨 브랜드 본사] (클러스터)
    │
    ├── [치킨 메뉴팀] (서비스)
    │       ├── 강남점 (태스크)
    │       │     └── 주방장, 홀매니저, 재고관리자 (컨테이너들)
    │       └── 신촌점 (태스크)
    │
    └── [피자 메뉴팀] (서비스)
            └── 홍대점 (태스크)`

---

## 5단계: 로드 밸런서란?

### 로드 밸런서의 역할

**문제 상황:**

`태스크가 3개 복제되어 있을 때
사용자는 어느 태스크로 접속해야 할까?`

**로드 밸런서 없이:**

`[사용자] → ??? → [태스크 1]
                [태스크 2]
                [태스크 3]`

**로드 밸런서 사용:**

`[사용자] → [로드 밸런서] → [태스크 1]
[태스크 2]
[태스크 3]

로드 밸런서가 자동으로 트래픽을 분산`

### 로드 밸런서의 기능

**1. 트래픽 분산**

`요청 1 → 태스크 1
요청 2 → 태스크 2
요청 3 → 태스크 3
요청 4 → 태스크 1 (다시 처음부터)`

**2. 헬스 체크**

`태스크 1 → 정상 ✓
태스크 2 → 응답 없음 ✗ (트래픽 보내지 않음)
태스크 3 → 정상 ✓`

**3. 자동 확장 지원**

`트래픽 증가 → 태스크 추가 → 로드 밸런서가 자동으로 새 태스크에도 분산`

### 왜 필요한가?

- ✅ 사용자는 하나의 주소로만 접속
- ✅ 백엔드에서 태스크를 자유롭게 추가/제거 가능
- ✅ 고장난 태스크는 자동으로 제외
- ✅ 트래픽을 균등하게 분산

### Nginx도 로드 밸런서가 될 수 있음

Nginx 설정 예시:

nginx

`upstream backend {
server server1:8080;
server server2:8080;
server server3:8080;
}

server {
listen 80;
location / {
proxy_pass http://backend;
}
}`

---

## 6단계: ECS 배포 준비하기

### Docker Hub에 이미지 올리기

**1. Docker Hub 회원가입**

- [https://hub.docker.com](https://hub.docker.com/) 에서 가입
- 무료로 사용 가능

**2. 로그인**

bash

`docker login`

Username과 Password 입력

**3. 이미지에 태그 붙이기**

bash

`*# 형식: docker tag [현재이미지명] [dockerhub아이디]/[이미지명]:[버전]*
docker tag nginx:1 myusername/nginx:1.0
docker tag webserver:1 myusername/webserver:1.0`

**4. 이미지 푸시**

bash

`docker push myusername/nginx:1.0
docker push myusername/webserver:1.0`

**5. Docker Hub에서 확인**

- Docker Hub 웹사이트에서 업로드된 이미지 확인
- Public 이미지는 누구나 다운로드 가능

### Nginx 설정 수정하기

**중요한 변경사항:**

ECS의 같은 태스크 안에 있는 컨테이너들은 `localhost`로 통신합니다!

**이전 설정 (8강):**

nginx

`server {
    listen 80;
    location / {
        proxy_pass http://host.docker.internal:8080;  *# 또는 다른 방법*
    }
}`

**ECS용 설정 (9강):**

nginx

`server {
    listen 80;
    location / {
        proxy_pass http://localhost:8080;  *# localhost로 변경!*
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        proxy_set_header X-Forwarded-Proto $scheme;
    }
}`

**왜 localhost를 쓰나요?**

ECS 태스크 안의 컨테이너들은 네트워크를 공유합니다:

`[태스크]
├── Nginx 컨테이너 (80번 포트)
└── 웹서버 컨테이너 (8080번 포트)
    ↑
    같은 네트워크 공간 → localhost로 접근 가능!`

**주의사항:**

- ❌ 같은 태스크 안에서 포트 번호가 겹치면 안 됨
- ✅ Nginx: 80번, 웹서버: 8080번처럼 다르게 설정

**다시 빌드하고 푸시:**

bash

`*# 설정 파일 수정 후*
docker build -t myusername/nginx:1.0 .
docker push myusername/nginx:1.0`

---

## 🎓 핵심 요약

### 배포의 진화

`집 컴퓨터 배포 → 클라우드 배포 → Docker 배포 → Orchestration`

### 마이크로서비스

- 기능을 독립적인 서비스로 분리
- 장점: 확장성, 독립 배포, 장애 격리
- 단점: 복잡성, 통신 오버헤드, 초기 비용
- 원칙: 처음엔 모놀리식, 필요할 때 점진적으로 분리

### ECS 구조

`클러스터 → 서비스 → 태스크 → 컨테이너`

- 클러스터: 프로젝트
- 서비스: 마이크로서비스
- 태스크: 함께 실행할 컨테이너 묶음 (Docker Compose 같은 것)
- 컨테이너: 실제 프로그램

### 로드 밸런서

- 여러 태스크에 트래픽 분산
- 헬스 체크로 정상 태스크만 사용
- 사용자는 하나의 주소로 접속

### ECS 배포 준비

1. Docker Hub에 이미지 업로드
2. Nginx 설정을 `localhost:8080`으로 수정
3. 같은 태스크 내 컨테이너는 포트 번호를 다르게 설정

```bash
# 1. 로그인
docker login

# 2. 이미지 빌드
docker build -t nginx-custom .
docker build -t webserver .

# 3. 태그 붙이기
docker tag nginx-custom myusername/nginx:1.0
docker tag webserver myusername/webserver:1.0

# 4. 푸시
docker push myusername/nginx:1.0
docker push myusername/webserver:1.0

# 5. 확인 (다른 곳에서)
docker pull myusername/nginx:1.0
docker run -d -p 80:80 myusername/nginx:1.0
```

---

## 🔍 다음 단계

다음 튜토리얼에서는:

- AWS ECS 클러스터 실제로 만들기
- 서비스와 태스크 설정하기
- 로드 밸런서 연결하기
- 실제 배포 및 테스트

---

## 💡 연습 문제

1. 모놀리식과 마이크로서비스의 차이점을 설명해보세요
2. ECS의 클러스터, 서비스, 태스크, 컨테이너의 관계를 그림으로 그려보세요
3. 로드 밸런서가 없을 때 어떤 문제가 발생할까요?
4. 본인의 Nginx와 웹서버 이미지를 Docker Hub에 올려보세요
5. 같은 태스크 안에서 포트 번호를 왜 다르게 설정해야 할까요?

---

# 강의 스크립트

**0:00 서버 배포는 어떻게 해요**

**1:55 실제상황을 가정해보자**

**4:34 로드밸런서**

**5:12 오케스트레이션 장단점**

**6:01 다음시간 준비**

배포같은거 어떻게 하냐고 물어보시는데

이미 여러분들 컴퓨터에서 서버가 잘 돌아가고 있기 때문에

다른 사람들이 "내아이피주소:8080"으로 들어가면 여러분들 서버를 만날 수 있습니다.

근데 컴퓨터를 24시간 켜두기도 그렇고 집컴퓨터는 IP주소도 자주 바뀌기 때문에

AWS 이런 곳에서 컴퓨터를 빌려서 거기에 서버를 띄워놓는게 안정적입니다.

그래서 1. 환경셋팅하고 2. 코드짜거나 거기로 옮기고 3. 실행하고 그런 작업을

AWS에서 컴퓨터를 하나 빌려서 동일하게 하면 배포 끝입니다.

하지만 직접 하는건 매우 귀찮기 때문에

- 내 코드를 이미지로 만들어서 어디 올리고
- 이미지를 AWS 컴퓨터에서 다운받고
- AWS 컴퓨터에 도커같은거 설치해서 이미지를 실행해두는게 끝임

> 마이크로서비스 등장

이미지로 배포하면 배포과정이 매우 쉬워집니다.

이미지 다운 받아서 실행누르면 끝이니까요.

근데 몸이 편해지면 사람들이 슬슬 이상한 짓을 하기 시작합니다.

![](https://d2hxk0kgvzehcg.cloudfront.net/wp-content/uploads/2024/11/%EC%A0%9C%EB%AA%A9-%EC%97%86%EC%9D%8C1.png)

서버의 여러 기능들을 하나의 프로그램에 넣는게 아니라

기능을 분리해서 각각 별도의 프로그램으로 만들고 각각 개별적인 컨테이너로 띄워둡니다.

그리고 컨테이너들은 필요할 때만 서로 통신하도록 설정합니다.

이런 방식을 **마이크로서비스 아키텍처**라고 부릅니다.

그러다보니 컨테이너 수가 많아지고

이걸 관리하기 위해서 container orchestration 툴을 사용하는 경우가 늘어나고 있습니다.

그래서 우리도 그걸 맛보도록 합시다.

솔직히 컨테이너가 몇 개 없을 때는 별로 필요없는데

내 몸값에 거품을 만들고 싶다면 남들이 어려워하는 기술을 일부러라도 써보는게 좋습니다.

> 컨테이너 orchestration tool

orchestration 툴은 쿠버네티스가 가장 유명합니다.

직접 여러분이 컴퓨터에 설치해서 운영하고 그래도 되긴 하는데

사이즈가 커지면 관리형 쿠버네티스 서비스를 쓰는 경우들이 많습니다.

![](https://d2hxk0kgvzehcg.cloudfront.net/wp-content/uploads/2024/11/%EC%A0%9C%EB%AA%A9-%EC%97%86%EC%9D%8C1-1.png)

▲ 이런 상품들이 있는데 직접 셋팅하는 것 보다 편하게 쿠버네티스를 사용할 수 있습니다.

근데 이런 것도 입문하려면 새로 배울게 좀 많기 때문에

훨씬 쉽고 간단한데 기능은 비슷한 ECS를 써서 입문해보도록 합시다. AWS에서 만든 orchestration 툴입니다.

> 실은 저런거 안써도 세상이 좋아짐

아니면 서버를 만들고 있다면 그걸 더 쉽게 배포할 수 있는 방법이 요즘은 많습니다.

- 이미지나 코드를 쉽게 배포해주는 상품 (Google cloud app engine, Google cloud run, AWS Elastic beanstalk)
- 쿠버네티스를 쓰고 싶은데 관리하기 싫으면 쓰는 상품 (GKE autopilot)
- AWS ECS를 쓰는데 명령어 한두개만으로 ECS에 배포해주는 툴 (AWS Copilot)
- 아니면 배포를 더 쉽게 만들어주는 Fly.io, Heroku, Vercel같은 서비스도 나와있습니다. 다만 한국 리전은 없는 경우도 있음

참고로 Fly.io 같은 서비스는 이미지를 올리면 이미지를 해체해서 Firecracker같은 VM에 올려서 서비스합니다.

왜냐면 컨테이너들은 같은 커널을 공유하기 때문에 보안이슈가 있을 수 있는데

그걸 원천차단하기 위해서 컨테이너말고 가벼운 VM을 쓰는 건데 그럴 수도 있다는걸 참고합시다.

> 서버를 만들었다고 가정해보자

실제 상황부터 한번 가정해봅시다.

마이크로서비스가 좋다니까 여러분이 1. 회원서버 2. 게시판서버를 개발해놓은겁니다.

이 마이크로서비스들을 배포하고 싶으면 어떻게 하냐면

컴퓨터 2개 빌려서 각각 띄워둬도 되는데 우리는 AWS에 있는 ECS를 써볼겁니다.

그걸 쓰면 어떤 식으로 하냐면...

![](https://d2hxk0kgvzehcg.cloudfront.net/wp-content/uploads/2024/11/%EA%B7%B8%EB%A6%BC1-1.png)

▲ ECS의 경우에는 클러스터안에 서비스 안에 태스크 안에 컨테이너들을 띄우게 되어있습니다.

- 클러스터는 하나의 프로젝트
- 서비스는 하나의 마이크로서비스
- 태스크는 서로 붙어있어야할 컨테이너들을 묶는 단위입니다.

그래서 지금 우리는 마이크로서비스가 2개 있으니까 서비스를 2개 만들고

서비스마다 필요한 nginx, 웹서버, DB 이미지들을 태스크 안에 감싸서 띄우면 되는겁니다.

태스크는 비유하자면 그냥 docker compose와 비슷한거라고 생각하면 되겠습니다.

참고로 태스크는 원하는 만큼 복제가 매우 쉽습니다.

![](https://d2hxk0kgvzehcg.cloudfront.net/wp-content/uploads/2024/11/%EA%B7%B8%EB%A6%BC2-1.png)

▲ 클러스터를 만들 때 컴퓨터를 몇대 빌릴지 예약할 수 있습니다.

그래서 빌린 컴퓨터마다 태스크들을 퍼트려놓는 것도 가능합니다.

그럼 컴퓨터 하나가 맛이가도 안전하겠군요.

그리고 볼륨장착, 컨테이너간 통신, 서비스간 통신 이런 것도 당연히 가능합니다.

![](https://d2hxk0kgvzehcg.cloudfront.net/wp-content/uploads/2024/11/%EA%B7%B8%EB%A6%BC5.png)

▲ 근데 생각해보면 서비스라는 부분은 필요없을 것 같지 않습니까?

실은 그렇긴 합니다. 그래서 서비스 생략하고 태스크만 띄울 수도 있긴 한데

서비스가 있으면

- 태스크를 쉽게 복제해주고
- 고장난 태스크는 새걸로 갈아치워주고
- 다른 서비스끼리 통신하고

이런게 쉬워져서 사용하는 레이어라고 보면 되겠습니다.

참고로 쿠버네티스도 이거랑 비슷하게 동작하는데 직접 컨트롤할 수 있는게 더 많을 뿐입니다.

> 치킨집으로 비유하자면

비유좋아하면 간단하게 치킨집으로 비유좀 해봅시다.

내가 **치킨 밀키트**를 만들었는데 그걸 고객들에게 맛을 보여주고 싶으면 어떻게 하겠습니까.

![](https://d2hxk0kgvzehcg.cloudfront.net/wp-content/uploads/2024/11/%EA%B7%B8%EB%A6%BC3.png)

▲ 치킨집 가맹본부 만들고 체인점을 만들고 그 안에서 치킨 밀키트를 조리하면 되겠습니다.

이번엔 **피자 밀키트**를 만들었으면

피자집 가맹본부 만들고 체인점을 만들고 그 안에서 피자 밀키트를 조리하면 되겠습니다.

가맹본부에선

- 체인점을 여러개 띄우고
- 필요없는 체인점은 줄이고
- 가맹본부끼리 소통하면서 콜라보하고

그런 행위가 가능합니다.

> load balancer

근데 이런거 쓰다보면 자주 필요한게 하나 있습니다.

로드밸런서라는 것인데 잠깐 설명하고 지나갑시다.

위에서 설명한 환경에선 서버를 복제해두고 싶으면 태스크를 복제해두면 됩니다.

근데 그러면 유저가 서버로 접속하고 싶을 때 대체 몇번째 태스크로 접속해야하는지 모르지 않습니까.

그럴 때 로드밸런서를 앞에 붙일 수 있습니다.

![](https://d2hxk0kgvzehcg.cloudfront.net/wp-content/uploads/2024/11/%EA%B7%B8%EB%A6%BC4.png)

로드밸런서는 그냥 간단한 프로그램인데

유저가 나한테 들어왔을 때 내 뒤에 있는 컴퓨터나 태스크들에 균등하게 안내해주는 역할을 하는 프로그램입니다.

참고로 nginx도 "누가 나에게 들어오면 뒤에 있는 여러 웹서버 중에 하나로 안내해주세요" 라고 코드짜놓을 수 있어서 로드밸런서같은 짓을 할 수 있습니다.

특히 컨테이너들이 서버리스 형태로 자원을 사용하는 경우에도 로드밸런서가 필요하게 될텐데

그래서 로드밸런서 프로그램을 하나 만들어두고

아무나 접속가능하게 만들고

누가 로드밸런서에 들어오면 서비스나 태스크를 가리키게 하면 이제 유저가 서버들로 접속할 수 있게 됩니다.

그래서 그것도 나중에 하나 만들어봅시다.

> 장단점

마이크로 서비스 형식으로 설계를 해두면 장점이 뭘까요.

- 유저가 많이 몰리는 그런 서비스가 있으면 그것만 딱 찝어서 CPU 사용량 늘리고 그럴 수 있어서 자원 사용이 효율적임
- 회원기능을 수정했으면 회원기능 서비스만 따로 배포하면 되니까 기능 업데이트도 매우 빨라짐

그래서 이딴 짓을 하는 겁니다.

단점은 뭐게요?

- 마이크로 서비스끼리 통신해야하면 그게 좀 귀찮아짐
- 마이크로 서비스가 많아지면 그걸 관리하는데 시간과 인력이 추가로 필요함
- 서버비도 초반엔 비쌈

그래서 처음부터 모든걸 마이크로 서비스로 만드는 것 보다는

기존처럼 한 프로그램에 모든걸 넣어서 개발하다가 기능이 너무 크고 비대해지는 부분이 있으면

그걸 마이크로 서비스로 슬쩍 빼보면서 시작하는게 좋은 관습입니다.

> 실제로 올려보기 전에 셋팅할게 있음

그래서 AWS ECS에 웹서버, nginx 만든걸 띄워볼 것인데 그 전에 셋팅할게 있습니다.

1. 이미지들을 리포지토리에 미리 올려둡시다.

AWS ECR이라는곳도 있는데 docker hub 공짜니까 거기 퍼블릭 리포지토리에 올려둡시다.

어딘가에 올려둬야 쉽게 가져다가 배포할 수 있으니까요.

2. 태스크 안에 있는 컨테이너들은 서로 **http://localhost:포트**로 통신해야합니다.

그래서 nginx가 웹서버 컨테이너를 부를 때 localhost:8080이런 식으로 부르도록 수정해봅시다.

```perl
(어쩌구.conf)

server {
        listen 80;
        location / {
            proxy_pass http://localhost:8080;
            proxy_set_header Host $host;
            proxy_set_header X-Real-IP $remote_addr;
            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
            proxy_set_header X-Forwarded-Proto $scheme;
        }
}

```

웹서버는 8080번 포트에 띄워놨기 때문에

웹서버 부르려면 http://localhost:8080 이런 식으로 주소를 입력해야합니다.

그래서 참고로 같은 태스크 안에 있는 컨테이너끼리 포트 번호가 겹치고 그러면 안됩니다.

나중에 다른 서비스에 있는 태스크를 부르려면 localhost:8080 자리에 다른 서비스 이름을 적으면 됩니다.

아무튼 nginx, 웹서버 이미지들 빌드하고 docker hub에 올려놓읍시다.
