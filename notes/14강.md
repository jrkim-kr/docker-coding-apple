# 14. Orchestration 1. 태스크, 서비스, 클러스터 개념정리

# 핵심 정리

## 🎯 학습 목표

이 튜토리얼을 마치면 다음을 할 수 있습니다:

- 서버 배포의 기본 개념 이해
- 마이크로서비스 아키텍처의 장단점 파악
- Container Orchestration의 필요성 이해
- AWS ECS의 기본 구조 이해
- 로드 밸런서의 역할 파악
- ECS 배포를 위한 준비 과정 이해

---

## 📚 사전 지식

- Docker 기본 명령어 (build, run, push)
- Nginx 리버스 프록시 개념
- 포트와 네트워크 기본 개념
- AWS 계정 (실습용)

---

## 1단계: 서버 배포의 기본 이해

### 일반적인 배포 방식

서버를 만들었다면 다른 사람들이 접속할 수 있게 배포해야 합니다.

**집 컴퓨터에서 실행하는 경우:**

`[사용자] → [내 IP 주소:8080] → [내 컴퓨터의 서버]`

**문제점:**

- ❌ 24시간 컴퓨터를 켜두어야 함
- ❌ 가정용 인터넷은 IP 주소가 자주 바뀜
- ❌ 전기세와 성능 문제

**해결책: 클라우드 서버 사용**

`[사용자] → [AWS 서버 IP:8080] → [AWS의 서버]`

AWS, Google Cloud, Azure 등에서 컴퓨터를 빌려서 서버를 실행합니다.

### Docker를 활용한 배포

**전통적인 방법:**

1. AWS 컴퓨터에 접속
2. 필요한 프로그램 설치 (Node.js, Python 등)
3. 코드 업로드
4. 실행

**Docker를 사용한 방법:**

1. 내 코드를 Docker 이미지로 만들기
2. 이미지를 Docker Hub 같은 곳에 업로드
3. AWS 컴퓨터에서 이미지 다운로드
4. `docker run` 명령어로 실행

**장점:**

- ✅ 환경 설정이 이미지에 포함되어 있음
- ✅ 배포 과정이 매우 간단함
- ✅ 어디서든 동일하게 실행됨

---

## 2단계: 마이크로서비스란?

### 모놀리식 vs 마이크로서비스

**모놀리식 (Monolithic):**

`[하나의 큰 서버 프로그램]
├── 회원 기능
├── 게시판 기능
├── 결제 기능
└── 알림 기능`

모든 기능이 하나의 프로그램 안에 들어있습니다.

**마이크로서비스 (Microservices):**

`[회원 서버]  [게시판 서버]  [결제 서버]  [알림 서버]
    ↓            ↓            ↓            ↓
[컨테이너 1] [컨테이너 2] [컨테이너 3] [컨테이너 4]`

각 기능을 독립적인 프로그램으로 분리하여 각각 컨테이너로 실행합니다.

### 마이크로서비스의 장단점

**장점:**

- ✅ **확장성**: 트래픽이 많은 서비스만 서버를 늘릴 수 있음
- ✅ **독립 배포**: 한 기능만 수정해도 해당 서비스만 재배포 가능
- ✅ **장애 격리**: 한 서비스에 문제가 생겨도 다른 서비스는 정상 동작
- ✅ **기술 선택의 자유**: 각 서비스마다 다른 언어/프레임워크 사용 가능

**단점:**

- ❌ **복잡성 증가**: 관리해야 할 서비스가 많아짐
- ❌ **통신 오버헤드**: 서비스 간 네트워크 통신 필요
- ❌ **초기 비용**: 처음에는 서버 비용이 더 들 수 있음
- ❌ **관리 인력 필요**: 여러 서비스를 관리하는 인력과 시간 필요

### 언제 사용해야 할까?

**처음에는:**

`모든 기능을 하나의 프로그램에 넣어서 개발
(모놀리식 방식)`

**나중에:**

`특정 기능이 너무 크거나 자주 변경된다면
→ 그 부분만 마이크로서비스로 분리`

**핵심 원칙**: 처음부터 모든 것을 마이크로서비스로 만들지 말고, 필요할 때 점진적으로 분리하세요.

---

## 3단계: Container Orchestration 이해하기

### 왜 필요한가?

**문제 상황:**

`컨테이너가 10개, 20개, 100개...
각각 관리하기가 너무 복잡함!`

**Container Orchestration이 해결하는 것들:**

- 🎯 **자동 배포**: 컨테이너를 쉽게 띄우고 내릴 수 있음
- 🎯 **스케일링**: 트래픽에 따라 컨테이너 개수를 자동으로 조절
- 🎯 **자동 복구**: 컨테이너가 죽으면 자동으로 재시작
- 🎯 **로드 밸런싱**: 트래픽을 여러 컨테이너에 분산
- 🎯 **네트워크 관리**: 컨테이너 간 통신 설정

### 주요 도구들

**1. Kubernetes (쿠버네티스)**

- 가장 유명하고 강력함
- 복잡하지만 기능이 많음
- Google, AWS, Azure 모두 지원

**관리형 쿠버네티스 서비스:**

- Google Kubernetes Engine (GKE)
- Amazon Elastic Kubernetes Service (EKS)
- Azure Kubernetes Service (AKS)

**2. AWS ECS (Elastic Container Service)**

- AWS에서 만든 간단한 orchestration 도구
- 쿠버네티스보다 배우기 쉬움
- AWS 서비스와 잘 연동됨

**3. 간편 배포 서비스들:**

- Google Cloud Run
- AWS Elastic Beanstalk
- Fly.io
- Heroku
- Vercel

---

## 4단계: AWS ECS 구조 이해

### ECS의 계층 구조

`클러스터 (Cluster)
    ↓
서비스 (Service)
    ↓
태스크 (Task)
    ↓
컨테이너 (Container)`

**각 계층 설명:**

**1. 클러스터 (Cluster)**

- 전체 프로젝트를 담는 가장 큰 단위
- "우리 회사 서버들의 집합"

**2. 서비스 (Service)**

- 하나의 마이크로서비스를 의미
- 예: 회원 서비스, 게시판 서비스, 결제 서비스
- 태스크를 자동으로 복제하고 관리함

**3. 태스크 (Task)**

- 함께 실행되어야 하는 컨테이너들의 묶음
- Docker Compose와 비슷한 개념
- 예: Nginx + 웹서버 + DB를 하나의 태스크로 묶음

**4. 컨테이너 (Container)**

- 실제 프로그램이 실행되는 단위

### 실제 예시

**회원 서버 + 게시판 서버를 ECS로 배포:**

`[클러스터: 우리 프로젝트]
    │
    ├── [서비스 1: 회원 서비스]
    │       └── [태스크 1]
    │               ├── Nginx 컨테이너
    │               ├── 회원 웹서버 컨테이너
    │               └── DB 컨테이너
    │
    └── [서비스 2: 게시판 서비스]
            └── [태스크 1]
                    ├── Nginx 컨테이너
                    ├── 게시판 웹서버 컨테이너
                    └── DB 컨테이너`

**태스크 복제 예시:**

`[서비스: 회원 서비스]
    ├── [태스크 1] ← 컴퓨터 1에서 실행
    ├── [태스크 2] ← 컴퓨터 1에서 실행
    └── [태스크 3] ← 컴퓨터 2에서 실행`

- 트래픽이 많으면 태스크를 여러 개 복제
- 한 컴퓨터가 고장나도 다른 컴퓨터에서 계속 실행

### 치킨집 비유로 이해하기

**클러스터 = 프랜차이즈 본사**

`"치킨 브랜드 본사"`

**서비스 = 메뉴 카테고리**

`치킨 메뉴팀, 피자 메뉴팀`

**태스크 = 실제 매장**

`강남점, 신촌점, 홍대점`

**컨테이너 = 매장 안의 직원/장비**

`주방장(웹서버), 홀 매니저(Nginx), 재고 관리자(DB)`

**예시:**

`[치킨 브랜드 본사] (클러스터)
    │
    ├── [치킨 메뉴팀] (서비스)
    │       ├── 강남점 (태스크)
    │       │     └── 주방장, 홀매니저, 재고관리자 (컨테이너들)
    │       └── 신촌점 (태스크)
    │
    └── [피자 메뉴팀] (서비스)
            └── 홍대점 (태스크)`

---

## 5단계: 로드 밸런서란?

### 로드 밸런서의 역할

**문제 상황:**

`태스크가 3개 복제되어 있을 때
사용자는 어느 태스크로 접속해야 할까?`

**로드 밸런서 없이:**

`[사용자] → ??? → [태스크 1]
                [태스크 2]
                [태스크 3]`

**로드 밸런서 사용:**

`[사용자] → [로드 밸런서] → [태스크 1]
[태스크 2]
[태스크 3]

로드 밸런서가 자동으로 트래픽을 분산`

### 로드 밸런서의 기능

**1. 트래픽 분산**

`요청 1 → 태스크 1
요청 2 → 태스크 2
요청 3 → 태스크 3
요청 4 → 태스크 1 (다시 처음부터)`

**2. 헬스 체크**

`태스크 1 → 정상 ✓
태스크 2 → 응답 없음 ✗ (트래픽 보내지 않음)
태스크 3 → 정상 ✓`

**3. 자동 확장 지원**

`트래픽 증가 → 태스크 추가 → 로드 밸런서가 자동으로 새 태스크에도 분산`

### 왜 필요한가?

- ✅ 사용자는 하나의 주소로만 접속
- ✅ 백엔드에서 태스크를 자유롭게 추가/제거 가능
- ✅ 고장난 태스크는 자동으로 제외
- ✅ 트래픽을 균등하게 분산

### Nginx도 로드 밸런서가 될 수 있음

Nginx 설정 예시:

nginx

`upstream backend {
server server1:8080;
server server2:8080;
server server3:8080;
}

server {
listen 80;
location / {
proxy_pass http://backend;
}
}`

---

## 6단계: ECS 배포 준비하기

### Docker Hub에 이미지 올리기

**1. Docker Hub 회원가입**

- [https://hub.docker.com](https://hub.docker.com/) 에서 가입
- 무료로 사용 가능

**2. 로그인**

bash

`docker login`

Username과 Password 입력

**3. 이미지에 태그 붙이기**

bash

`*# 형식: docker tag [현재이미지명] [dockerhub아이디]/[이미지명]:[버전]*
docker tag nginx:1 myusername/nginx:1.0
docker tag webserver:1 myusername/webserver:1.0`

**4. 이미지 푸시**

bash

`docker push myusername/nginx:1.0
docker push myusername/webserver:1.0`

**5. Docker Hub에서 확인**

- Docker Hub 웹사이트에서 업로드된 이미지 확인
- Public 이미지는 누구나 다운로드 가능

### Nginx 설정 수정하기

**중요한 변경사항:**

ECS의 같은 태스크 안에 있는 컨테이너들은 `localhost`로 통신합니다!

**이전 설정 (8강):**

nginx

`server {
    listen 80;
    location / {
        proxy_pass http://host.docker.internal:8080;  *# 또는 다른 방법*
    }
}`

**ECS용 설정 (9강):**

nginx

`server {
    listen 80;
    location / {
        proxy_pass http://localhost:8080;  *# localhost로 변경!*
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        proxy_set_header X-Forwarded-Proto $scheme;
    }
}`

**왜 localhost를 쓰나요?**

ECS 태스크 안의 컨테이너들은 네트워크를 공유합니다:

`[태스크]
├── Nginx 컨테이너 (80번 포트)
└── 웹서버 컨테이너 (8080번 포트)
    ↑
    같은 네트워크 공간 → localhost로 접근 가능!`

**주의사항:**

- ❌ 같은 태스크 안에서 포트 번호가 겹치면 안 됨
- ✅ Nginx: 80번, 웹서버: 8080번처럼 다르게 설정

**다시 빌드하고 푸시:**

bash

`*# 설정 파일 수정 후*
docker build -t myusername/nginx:1.0 .
docker push myusername/nginx:1.0`

---

## 🎓 핵심 요약

### 배포의 진화

`집 컴퓨터 배포 → 클라우드 배포 → Docker 배포 → Orchestration`

### 마이크로서비스

- 기능을 독립적인 서비스로 분리
- 장점: 확장성, 독립 배포, 장애 격리
- 단점: 복잡성, 통신 오버헤드, 초기 비용
- 원칙: 처음엔 모놀리식, 필요할 때 점진적으로 분리

### ECS 구조

`클러스터 → 서비스 → 태스크 → 컨테이너`

- 클러스터: 프로젝트
- 서비스: 마이크로서비스
- 태스크: 함께 실행할 컨테이너 묶음 (Docker Compose 같은 것)
- 컨테이너: 실제 프로그램

### 로드 밸런서

- 여러 태스크에 트래픽 분산
- 헬스 체크로 정상 태스크만 사용
- 사용자는 하나의 주소로 접속

### ECS 배포 준비

1. Docker Hub에 이미지 업로드
2. Nginx 설정을 `localhost:8080`으로 수정
3. 같은 태스크 내 컨테이너는 포트 번호를 다르게 설정

```bash
# 1. 로그인
docker login

# 2. 이미지 빌드
docker build -t nginx-custom .
docker build -t webserver .

# 3. 태그 붙이기
docker tag nginx-custom myusername/nginx:1.0
docker tag webserver myusername/webserver:1.0

# 4. 푸시
docker push myusername/nginx:1.0
docker push myusername/webserver:1.0

# 5. 확인 (다른 곳에서)
docker pull myusername/nginx:1.0
docker run -d -p 80:80 myusername/nginx:1.0
```

---

## 🔍 다음 단계

다음 튜토리얼에서는:

- AWS ECS 클러스터 실제로 만들기
- 서비스와 태스크 설정하기
- 로드 밸런서 연결하기
- 실제 배포 및 테스트

---

## 💡 연습 문제

1. 모놀리식과 마이크로서비스의 차이점을 설명해보세요
2. ECS의 클러스터, 서비스, 태스크, 컨테이너의 관계를 그림으로 그려보세요
3. 로드 밸런서가 없을 때 어떤 문제가 발생할까요?
4. 본인의 Nginx와 웹서버 이미지를 Docker Hub에 올려보세요
5. 같은 태스크 안에서 포트 번호를 왜 다르게 설정해야 할까요?

---
